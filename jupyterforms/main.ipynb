{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "81cf9c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import logging\n",
    "import pickle\n",
    "logging.basicConfig(filename='logging.log' , level= logging.INFO, format = '%(levelname)s, %(asctime)s %(message)s'  )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ba13c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc0a1f2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "7810284e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#make connection to the database\n",
    "try:  \n",
    "    import mysql.connector as conn\n",
    "    mydb = conn.connect(user = 'root',host = 'localhost', database = 'test5', passwd= '431170')\n",
    "    logging.info('Successfully connected the database')\n",
    "except Exception as e:\n",
    "    logging.exception(str(e)+ 'connection error')\n",
    "\n",
    "#make cursor and table in database\n",
    "try:\n",
    "    cursor = mydb.cursor()\n",
    "    cursor.execute('create table test5.class_algeria(day float, month float, humidity float , wind float, rain float, dmc float, dc float, spread float, region float, classes float)')\n",
    "    mydb.commit()\n",
    "    logging.info('table created')\n",
    "except Exception as e:\n",
    "    logging.exception(str(e )+ 'error occured while new table form')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "f5058aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    data = pd.read_csv('df_final_with10.csv', index_col=0)\n",
    "    sample_data = data.sample(20)\n",
    "    #scaling data\n",
    "    X_columns  = ['Humidity', 'Wind', 'Rain', 'DMC', 'DC', 'Spread']\n",
    "    X_scale = sample_data[X_columns]\n",
    "    from sklearn.preprocessing import MinMaxScaler\n",
    "    Mim_max_X = MinMaxScaler()\n",
    "    my_data = sample_data.copy()\n",
    "    X_part = pd.DataFrame(Mim_max_X.fit_transform(X_scale), columns = X_columns, index=sample_data.index)\n",
    "    my_data.drop(X_columns,axis = 1, inplace = True)\n",
    "    df_new = my_data.join(X_part)\n",
    "    col_order = ['Day',  'Month',  'Humidity',  'Wind',  'Rain',  'DMC',    'DC',  'Spread',  'Region',  'Classes']\n",
    "    df_new = df_new[col_order]\n",
    "    cursor = mydb.cursor()\n",
    "    cursor.execute('delete from test5.class_algeria')\n",
    "    mydb.commit()\n",
    "    for i, rows in df_new.iterrows():\n",
    "        row_in = tuple(rows)\n",
    "        cursor.execute('insert into test5.class_algeria values(%s, %s, %s, %s, %s, %s, %s, %s, %s, %s )', row_in)\n",
    "    mydb.commit()\n",
    "    logging.info('insertion completed successfully')\n",
    "except Exception as e:\n",
    "    logging.exception(str(e), 'error occured while insertion')\n",
    "    mydb.rollback()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "1ec9908f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, request, jsonify\n",
    "app = Flask(__name__)\n",
    "import logging \n",
    "logging.basicConfig(filename= 'logging.log', level= logging.INFO , message= '%(levelname)s, %(asctime)s, %(message)s')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "##buraya verileri fetch etmek kaliyor\n",
    "##sonra verileri x v y olarak ayir ve minmaxtan gecir\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "cb5305c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.route('/mass_class', methods = ['GET', 'POST'])\n",
    "def fetching_data():\n",
    " \n",
    "    try:\n",
    "        user = request.json['user']\n",
    "        host = request.json['host']\n",
    "        database = request.json['database']\n",
    "        password = request.json['password']\n",
    "        import mysql.connector as conn\n",
    "        mydb = conn.connect(user = user, host = host, database = database, passwd = password)\n",
    "        logging.info('connection is successfull')\n",
    "    except Exception as e:\n",
    "        logging.exception(str(e)+ 'error occured during connection to database')\n",
    "    try:\n",
    "        cursor = mydb.cursor()\n",
    "        cursor.execute('select * from class_algeria')\n",
    "        fetch_data = [list(i) for i in cursor.fetchall()]\n",
    "        down_data = pd.DataFrame(fetch_data, columns=('Day',  'Month',  'Humidity',  'Wind',  'Rain',  'DMC',    'DC',  'Spread',  'Region',  'Classes'))    \n",
    "        X_inserted = down_data.drop('Classes', axis =1)\n",
    "    except Exception as e:\n",
    "        logging.exception(str(e)+ 'sth happened while fetching data from database')\n",
    "    try:\n",
    "        loaded_class_model = pickle.load(open('class_model.pkl', 'rb'))\n",
    "        y_pred = loaded_class_model.predict(X_inserted)\n",
    "        y_modified = ['Fire' if i ==1  else 'Not Fire' for i in y_pred]\n",
    "        y_modified_s = str(y_modified)\n",
    "        return jsonify(y_modified_s)\n",
    "    except Exception as e:\n",
    "        logging.exception(str(e)+ 'sth happened while predicting the data with model')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "e2ab3237",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app \"__main__\" (lazy loading)\n",
      " * Environment: production\n",
      "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
      "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
      " * Debug mode: off\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    app.run(port = 8000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "80fc9973",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, request, jsonify\n",
    "app = Flask(__name__)\n",
    "import logging \n",
    "logging.basicConfig(filename= 'logging.log', level= logging.INFO , message= '%(levelname)s, %(asctime)s, %(message)s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "51aa01b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#make connection to the database\n",
    "try:  \n",
    "    app = Flask(__name__)\n",
    "    import mysql.connector as conn\n",
    "    mydb = conn.connect(user = 'root',host = 'localhost', database = 'test5', passwd= '431170')\n",
    "    logging.info('Successfully connected the database')\n",
    "except Exception as e:\n",
    "    logging.exception(str(e)+ 'connection error')\n",
    "\n",
    "#make cursor and table in database\n",
    "try:\n",
    "    cursor = mydb.cursor()\n",
    "    cursor.execute('create table test5.regression_algeria(day float, month float, humidity float , wind float, rain float, dmc float, dc float, spread float, region float, classes float)')\n",
    "    mydb.commit()\n",
    "    logging.info('table created')\n",
    "except Exception as e:\n",
    "    logging.exception(str(e )+ 'error occured while new table form')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "36c51318",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    data = pd.read_csv('df_final_with10.csv', index_col=0)\n",
    "    sample_data = data.sample(20)\n",
    "    #scaling data\n",
    "    X_columns  = ['Humidity', 'Wind',  'DMC', 'DC', 'Spread']\n",
    "    X_scale = sample_data[X_columns]\n",
    "    from sklearn.preprocessing import MinMaxScaler\n",
    "    Mim_max_X = MinMaxScaler()\n",
    "    my_data = sample_data.copy()\n",
    "    X_part = pd.DataFrame(Mim_max_X.fit_transform(X_scale), columns = X_columns, index=sample_data.index)\n",
    "    my_data.drop(X_columns,axis = 1, inplace = True)\n",
    "    df_new = my_data.join(X_part)\n",
    "    col_order = ['Day',  'Month',  'Humidity',  'Wind',  'Rain',  'DMC',    'DC',  'Spread',  'Region',  'Classes']\n",
    "    df_new = df_new[col_order]\n",
    "    cursor = mydb.cursor()\n",
    "    cursor.execute('delete from test5.regression_algeria')\n",
    "    mydb.commit()\n",
    "    for i, rows in df_new.iterrows():\n",
    "        row_in = tuple(rows)\n",
    "        cursor.execute('insert into test5.regression_algeria values(%s, %s, %s, %s, %s, %s, %s, %s, %s, %s )', row_in)\n",
    "    mydb.commit()\n",
    "    logging.info('insertion completed successfully')\n",
    "except Exception as e:\n",
    "    logging.exception(str(e), 'error occured while insertion')\n",
    "    mydb.rollback()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "6e9d6382",
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.route('/mass_regress', methods = ['GET', 'POST'])\n",
    "def fetchingreg_data():\n",
    "    \n",
    "    try:\n",
    "        user = request.json['user']\n",
    "        host = request.json['host']\n",
    "        database = request.json['database']\n",
    "        password = request.json['password']\n",
    "        import mysql.connector as conn\n",
    "        mydb = conn.connect(user = user, host = host, database = database, passwd = password)\n",
    "        logging.info('connection is successfull')\n",
    "    except Exception as e:\n",
    "        logging.exception(str(e)+ 'error occured during connection to database')\n",
    "    try:\n",
    "        cursor = mydb.cursor()\n",
    "        cursor.execute('select * from regression_algeria')\n",
    "        fetch_data = [list(i) for i in cursor.fetchall()]\n",
    "        down_data = pd.DataFrame(fetch_data, columns=('Day',  'Month',  'Humidity',  'Wind',  'Rain',  'DMC',    'DC',  'Spread',  'Region',  'Classes'))    \n",
    "        X_inserted = down_data.drop('Rain', axis =1)\n",
    "    except Exception as e:\n",
    "        logging.exception(str(e)+ 'sth happened while fetching data from database')\n",
    "    try:\n",
    "        loaded_class_model = pickle.load(open('regression_model.pkl', 'rb'))\n",
    "        y_pred = loaded_class_model.predict(X_inserted)\n",
    "        #Mim_max_X.inverse_transform(y_pred.reshape(-1, 1))\n",
    "        y_modified_s = str(np.round(y_pred,2))\n",
    "        return jsonify(y_modified_s)\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.exception(str(e)+ 'sth happened while predicting the data with model')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9907e471",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "4adf5101",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app \"__main__\" (lazy loading)\n",
      " * Environment: production\n",
      "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
      "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
      " * Debug mode: off\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    app.run(port = 8000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "52cb4c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, request, jsonify\n",
    "app = Flask(__name__)\n",
    "import logging \n",
    "logging.basicConfig(filename= 'logging.log', level= logging.INFO , message= '%(levelname)s, %(asctime)s, %(message)s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "78a620f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.route('/single_regress', methods = ['POST'])\n",
    "def single_regression():\n",
    "    try:\n",
    "        data=request.json['data']\n",
    "        print(data)\n",
    "        new_data=[list(data.values())]\n",
    "    \n",
    "    except Exception as e:\n",
    "        logging.exception(str(e)+ 'error occured whıle fetchıng data from postman')\n",
    "\n",
    "    try:\n",
    "        loaded_class_model = pickle.load(open('regression_model.pkl', 'rb'))\n",
    "        y_pred = loaded_class_model.predict(new_data)[0]\n",
    "        y_modified_s = str(y_pred)\n",
    "        return jsonify(y_modified_s)\n",
    "    except Exception as e:\n",
    "        logging.exception(str(e)+ 'sth happened while predicting the data with model')\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "823af604",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app \"__main__\" (lazy loading)\n",
      " * Environment: production\n",
      "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
      "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
      " * Debug mode: off\n",
      "{'Day': 7, 'Month': 10, 'Humidity': 1, 'Wind': 1, 'DMC': 1, 'DC': 1, 'Spread': 0, 'Region': 0, 'Classes': 1}\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    app.run(port = 8000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "6c743b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, request, jsonify\n",
    "app = Flask(__name__)\n",
    "import logging \n",
    "logging.basicConfig(filename= 'logging.log', level= logging.INFO , message= '%(levelname)s, %(asctime)s, %(message)s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "4bfa7033",
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.route('/single_class', methods = ['POST'])\n",
    "def single_classif():\n",
    "    try:\n",
    "        data=request.json['data']\n",
    "        print(data)\n",
    "        new_data=[list(data.values())]\n",
    "    \n",
    "    except Exception as e:\n",
    "        logging.exception(str(e)+ 'error occured whıle fetchıng data from postman')\n",
    "\n",
    "    try:\n",
    "        loaded_class_model = pickle.load(open('class_model.pkl', 'rb'))\n",
    "        y_pred = loaded_class_model.predict(new_data)[0]\n",
    "        y_str = str(y_pred)\n",
    "        return jsonify(y_str)\n",
    "    except Exception as e:\n",
    "        logging.exception(str(e)+ 'sth happened while predicting the data with model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "c62473fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app \"__main__\" (lazy loading)\n",
      " * Environment: production\n",
      "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
      "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
      " * Debug mode: off\n",
      "{'Day': 7, 'Month': 10, 'Humidity': 1, 'Wind': 1, 'Rain': 0.4, 'DMC': 1, 'DC': 1, 'Spread': 0, 'Region': 0}\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    app.run(port = 8000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb93bf1a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
